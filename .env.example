# Project Velocity - Environment Configuration
# Copy this file to .env and fill in your values

# ===========================================
# LLM Configuration
# ===========================================

# LLM Provider: google | openai | anthropic | bedrock
LLM_PROVIDER=google

# Model name (optional - uses provider defaults if not set)
# Google: gemini-2.0-flash
# OpenAI: gpt-4o
# Anthropic: claude-3-opus-20240229
# Bedrock: anthropic.claude-3-sonnet-20240229-v1:0
LLM_MODEL=

# Generic API Key (or use provider-specific keys below)
LLM_API_KEY=

# Provider-specific API Keys (fallback if LLM_API_KEY not set)
GOOGLE_API_KEY=your_google_api_key_here
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# ===========================================
# Application Settings
# ===========================================

# Environment: development | production
# development = Uses simulator/mock responses
# production = Uses real LLM calls
ENVIRONMENT=development

# ===========================================
# Testing/Debug Flags
# ===========================================

# Force document verification to fail (for testing consultant flow)
SIMULATE_DOC_FAILURE=false
